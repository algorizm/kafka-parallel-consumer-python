# ì•„í‚¤í…ì²˜ ìƒì„¸ ë¬¸ì„œ

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#ì‹œìŠ¤í…œ-ê°œìš”)
2. [í•µì‹¬ ì»´í¬ë„ŒíŠ¸](#í•µì‹¬-ì»´í¬ë„ŒíŠ¸)
3. [ì²˜ë¦¬ íë¦„](#ì²˜ë¦¬-íë¦„)
4. [ì„¤ê³„ ê²°ì •](#ì„¤ê³„-ê²°ì •)
5. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)

---

## ì‹œìŠ¤í…œ ê°œìš”

### ëª©ì 
Kafkaì—ì„œ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³ , í•„í„°ë§ì„ ê±°ì³ HTTP APIë¡œ ìš”ì²­ì„ ì „ì†¡í•˜ëŠ” ê³ ì„±ëŠ¥ ì»¨ìŠˆë¨¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### í•µì‹¬ ìš”êµ¬ì‚¬í•­
1. **ìˆœì„œ ë³´ì¥**: ë©”ì‹œì§€ ì†Œë¹„ ìˆœì„œì— ë”°ë¥¸ HTTP ìš”ì²­ ìˆœì„œ ë³´ì¥
2. **ê³ ì„±ëŠ¥**: ë†’ì€ ì²˜ë¦¬ëŸ‰ í™•ë³´
3. **ì•ˆì •ì„±**: ì—ëŸ¬ ì²˜ë¦¬, ì¬ì‹œë„, ì•ˆì „í•œ ì¢…ë£Œ
4. **í™•ì¥ì„±**: í”„ë¡œì„¸ìŠ¤/ìŠ¤ë ˆë“œ ìˆ˜ ì¡°ì ˆ ê°€ëŠ¥

---

## í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### 1. ConsumerMain (`base_process_consumer.py`)

**ì—­í• :**
- Kafka ë©”ì‹œì§€ ì†Œë¹„
- í•„í„° ì ìš© ë° RequestURIMap ìƒì„±
- í ê´€ë¦¬ ë° ì›Œì»¤ ìŠ¤ë ˆë“œ ê´€ë¦¬
- Offset ì»¤ë°‹ ìŠ¤ì¼€ì¤„ë§

**ì£¼ìš” ë©”ì„œë“œ:**
```python
class ConsumerMain:
    def consume(self, partition_no: int = None):
        """Kafka ë©”ì‹œì§€ ì†Œë¹„ ë° íì— ì¶”ê°€"""
        
    def start_concurrent_request(self, number: int = 1):
        """ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘"""
        
    def wait_done(self):
        """ì•ˆì „í•œ ì¢…ë£Œ ì²˜ë¦¬"""
```

**í•µì‹¬ ë¡œì§:**
```python
# ë©”ì‹œì§€ ì†Œë¹„
msg = self.consumer.poll(0.1)

# í•„í„° ì ìš©
filter_map = apply_filter(payload=self.payload, key=self.key)

# RequestURIMap ë¦¬ìŠ¤íŠ¸ ìƒì„±
_req_uri_map_list: list[RequestURIMap] = []
for _filter_result in filter_map:
    _req_map = make_request_map_with_offset(...)
    _req_uri_map_list.append(_req_map)

# íì— ë©”ì‹œì§€ ë‹¨ìœ„ë¡œ ì¶”ê°€
self.request_queue.put(_req_uri_map_list)
```

### 2. SendHttpWorker (`base_process_worker.py`)

**ì—­í• :**
- íì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
- HTTP ìš”ì²­ ìˆœì°¨ ì²˜ë¦¬
- Offset ì—…ë°ì´íŠ¸

**í•µì‹¬ ë¡œì§:**
```python
class SendHttpWorker(Thread):
    def run(self):
        while not self.event.is_set():
            record = self.queue.get(timeout=1)
            self.process_http_requests(record)
    
    def process_http_requests(self, request_items: List[RequestURIMap]):
        """HTTP ìš”ì²­ ìˆœì°¨ ì²˜ë¦¬"""
        for item in request_items:
            if item.request_type is not RequestType.NO_BEHAVIOR:
                self.request_uri_no_session_map(req_map=item)
```

### 3. Filter System (`parallel_consumer/filter/`)

**ì—­í• :**
- ë©”ì‹œì§€ íƒ€ì…ë³„ í•„í„°ë§ ë¡œì§
- RequestURIMap ìƒì„±
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì ìš©

**í•„í„° ì˜ˆì‹œ:**
```python
def filter_live_prc_que_from_pd_prd(payload: dict) -> FilterResultMap:
    """ìƒí’ˆ ì •ë³´ë¡œë¶€í„° ê°€ê²© í í•„í„°ë§"""
    # í•„í„°ë§ ë¡œì§
    # ...
    return FilterResultMap(...)
```

### 4. Request Handler (`parallel_consumer/utils/request.py`)

**ì—­í• :**
- HTTP ìš”ì²­ ì²˜ë¦¬
- ì¬ì‹œë„ ë¡œì§
- ì—ëŸ¬ ì²˜ë¦¬

**í•µì‹¬ í•¨ìˆ˜:**
```python
def request_uri_no_session_map(worker_name: str, req_map: RequestURIMap):
    """ë§¤ ìš”ì²­ë§ˆë‹¤ ìƒˆ ì„¸ì…˜ìœ¼ë¡œ HTTP ìš”ì²­"""
    with requests.session() as session:
        response = session.post(
            req_map.request_uri,
            headers=headers,
            json=req_map.request_body,
            timeout=HTTP_REQUEST_TIMEOUT,
        )
```

---

## ì²˜ë¦¬ íë¦„

### 1. ë©”ì‹œì§€ ì†Œë¹„ ë‹¨ê³„

```
Kafka Broker
    â†“
ConsumerMain.consume()
    â†“
ë©”ì‹œì§€ íŒŒì‹± (parse_to_payload)
    â†“
í•„í„° ì ìš© (apply_filter)
    â†“
RequestURIMap ë¦¬ìŠ¤íŠ¸ ìƒì„±
    â†“
íì— ì¶”ê°€ (request_queue.put)
```

### 2. HTTP ìš”ì²­ ì²˜ë¦¬ ë‹¨ê³„

```
íì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸° (queue.get)
    â†“
ì›Œì»¤ ìŠ¤ë ˆë“œê°€ ë©”ì‹œì§€ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    â†“
ìˆœì°¨ ì²˜ë¦¬ (for loop)
    â†“
HTTP ìš”ì²­ (request_uri_no_session_map)
    â†“
Offset ì—…ë°ì´íŠ¸ (update_offset_queue)
```

### 3. Offset ì»¤ë°‹ ë‹¨ê³„

```
Offset íì— ì¶”ê°€ (offset_queue.put)
    â†“
ìŠ¤ì¼€ì¤„ëŸ¬ì— ì˜í•´ ì£¼ê¸°ì  ì»¤ë°‹
    â†“
Kafka Brokerì— ì»¤ë°‹
```

---

## ì„¤ê³„ ê²°ì •

### 1. ë©€í‹°í”„ë¡œì„¸ìŠ¤ + ë©€í‹°ìŠ¤ë ˆë“œ

**ì´ìœ :**
- Python GIL ì œì•½ íšŒí”¼
- ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
- í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì¡°ì ˆë¡œ í™•ì¥ì„± í™•ë³´

**êµ¬í˜„:**
```python
# ë©€í‹°í”„ë¡œì„¸ìŠ¤
for i in range(NUMBER_OF_WORKERS):
    p = multiprocessing.Process(target=task, args=(process_event,))
    p.start()

# ë©€í‹°ìŠ¤ë ˆë“œ
def start_concurrent_request(self, number: int = 1):
    for num in range(1, number + 1):
        req_thread = SendHttpWorker(...)
        req_thread.start()
```

### 2. ë©”ì‹œì§€ ë‹¨ìœ„ í êµ¬ì¡°

**ì´ìœ :**
- ë©”ì‹œì§€ ë‚´ HTTP ìš”ì²­ ìˆœì„œ ë³´ì¥
- ì›ìì„± ë³´ì¥
- Offset ê´€ë¦¬ ìš©ì´

**êµ¬í˜„:**
```python
# ë©”ì‹œì§€ ë‹¨ìœ„ë¡œ íì— ì¶”ê°€
_req_uri_map_list: list[RequestURIMap] = []
for _filter_result in filter_map:
    _req_map = make_request_map_with_offset(...)
    _req_uri_map_list.append(_req_map)

self.request_queue.put(_req_uri_map_list)
```

### 3. ë™ê¸° HTTP ìš”ì²­

**ì´ìœ :**
- HTTP ìš”ì²­ ìˆœì„œ ë³´ì¥
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ ê°„ë‹¨
- ìš´ì˜ í™˜ê²½ ì•ˆì •ì„±

**êµ¬í˜„:**
```python
def process_http_requests(self, request_items: List[RequestURIMap]):
    for item in request_items:  # ìˆœì°¨ ì²˜ë¦¬
        self.request_uri_no_session_map(req_map=item)  # ë™ê¸° HTTP
```

### 4. ë§¤ ìš”ì²­ë§ˆë‹¤ ìƒˆ ì„¸ì…˜ ìƒì„±

**ì´ìœ :**
- L4 ë¡œë“œë°¸ëŸ°ì„œì˜ Session ê¸°ë°˜ ë¼ìš´ë“œ ë¡œë¹ˆ
- ë¡¤ë§ ë°°í¬ ì‹œ ì•ˆì •ì„± í™•ë³´
- íŠ¸ë˜í”½ ë¶„ì‚° ìµœì í™”

**êµ¬í˜„:**
```python
def request_uri_no_session_map(self, req_map: RequestURIMap):
    with requests.session() as session:  # ë§¤ ìš”ì²­ë§ˆë‹¤ ìƒˆ ì„¸ì…˜
        response = session.post(...)
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ë©€í‹°í”„ë¡œì„¸ìŠ¤
- GIL ì œì•½ íšŒí”¼
- CPU ì½”ì–´ í™œìš© ê·¹ëŒ€í™”
- í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì¡°ì ˆë¡œ í™•ì¥ì„± í™•ë³´

### 2. ë©€í‹°ìŠ¤ë ˆë“œ
- ì—¬ëŸ¬ ë©”ì‹œì§€ ë™ì‹œ ì²˜ë¦¬
- í ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬
- ìŠ¤ë ˆë“œ ìˆ˜ ì¡°ì ˆë¡œ ì²˜ë¦¬ëŸ‰ ì¡°ì ˆ

### 3. í ê´€ë¦¬
- í í¬ê¸° ì œí•œìœ¼ë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬
- íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¸”ë¡œí‚¹ ë°©ì§€
- ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´

### 4. Offset ì»¤ë°‹ ìµœì í™”
- ì£¼ê¸°ì  ì»¤ë°‹ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
- ë©”ì‹œì§€ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ì•ˆì „í•œ ì»¤ë°‹
- ìµœëŒ€ offset ì‚¬ìš©ìœ¼ë¡œ ì¤‘ë³µ ì»¤ë°‹ ë°©ì§€

---

## ì•ˆì •ì„± í™•ë³´

### 1. ì—ëŸ¬ ì²˜ë¦¬
- ì˜ˆì™¸ ì²˜ë¦¬ ë° ë¡œê¹…
- ì—ëŸ¬ ë°œìƒ ì‹œ ì•Œë¦¼ ì „ì†¡ (ìš´ì˜ í™˜ê²½)
- ì•ˆì „í•œ ì¢…ë£Œ ì²˜ë¦¬

### 2. ì¬ì‹œë„ ë¡œì§
- ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ì‹œ ì¬ì‹œë„
- ì¬ì‹œë„ íšŸìˆ˜ ì œí•œ
- íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬

### 3. ì¢…ë£Œ ì²˜ë¦¬
- SIGTERM/SIGINT ì‹ í˜¸ ì²˜ë¦¬
- í ë¹„ìš°ê¸°
- ìŠ¤ë ˆë“œ ì•ˆì „ ì¢…ë£Œ
- Offset ì»¤ë°‹

---

## ëª¨ë‹ˆí„°ë§

### 1. ë¡œê¹…
- ë©”ì‹œì§€ ì†Œë¹„ëŸ‰
- í í¬ê¸°
- HTTP ìš”ì²­ ì²˜ë¦¬ëŸ‰
- ì—ëŸ¬ ë¡œê·¸

### 2. ë©”íŠ¸ë¦­
- ì´ˆë‹¹ ë©”ì‹œì§€ ì†Œë¹„ëŸ‰
- ì´ˆë‹¹ HTTP ìš”ì²­ ì²˜ë¦¬ëŸ‰
- í í¬ê¸°
- ìŠ¤ë ˆë“œë³„ ì²˜ë¦¬ëŸ‰

---

## í™•ì¥ì„±

### 1. í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì¡°ì ˆ
```python
NUMBER_OF_WORKERS = 3  # í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì¡°ì ˆ
```

### 2. ìŠ¤ë ˆë“œ ìˆ˜ ì¡°ì ˆ
```python
CONCURRENT_REQUEST_THREAD_NUM = 15  # ìŠ¤ë ˆë“œ ìˆ˜ ì¡°ì ˆ
```

### 3. í í¬ê¸° ì¡°ì ˆ
```python
QUEUE_MAX_SIZE = 90000  # í í¬ê¸° ì¡°ì ˆ
```

---

## ì°¸ê³  ìë£Œ

- Kafka Consumer API: https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html
- Python Multiprocessing: https://docs.python.org/3/library/multiprocessing.html
- Python Threading: https://docs.python.org/3/library/threading.html

